{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41196d3f",
   "metadata": {},
   "source": [
    "# CNN + CapsGNN for GI Image Classification\n",
    "\n",
    "This notebook implements a hybrid model:\n",
    "- **CNN backbone** for local feature extraction\n",
    "- **Primary Capsules** for part-whole representation\n",
    "- **Graph Neural Network (CapsGNN)** over capsule nodes for relational reasoning\n",
    "\n",
    "Update `DATA_DIR` in Cell 2, then run all cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e186d05",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tqdm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mrandom\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tqdm'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# Reproducibility + Device\n",
    "# ---------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "# ---------------------------\n",
    "# Paths + Hyperparameters\n",
    "# ---------------------------\n",
    "# Set this to your Kvasir dataset root containing class folders\n",
    "DATA_DIR = r\"./kvasir-dataset-v2\"\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 35\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "K_NEIGHBORS = 8\n",
    "MAX_CAPS_NODES = 128\n",
    "EXPECTED_NUM_CLASSES = 8\n",
    "EARLY_STOPPING_PATIENCE = 7\n",
    "MIN_DELTA = 1e-4\n",
    "NUM_WORKERS = min(4, os.cpu_count() or 0)\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    raise FileNotFoundError(f\"DATA_DIR not found: {DATA_DIR}. Please update DATA_DIR in this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dc3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Dataset + DataLoaders (with augmentation)\n",
    "# ---------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.10, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "base_dataset = datasets.ImageFolder(DATA_DIR)\n",
    "class_names = base_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "if num_classes != EXPECTED_NUM_CLASSES:\n",
    "    raise ValueError(f\"Expected {EXPECTED_NUM_CLASSES} classes, but found {num_classes}: {class_names}\")\n",
    "\n",
    "n_samples = len(base_dataset)\n",
    "train_size = int(0.70 * n_samples)\n",
    "val_size = int(0.15 * n_samples)\n",
    "test_size = n_samples - train_size - val_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "indices = torch.randperm(n_samples, generator=generator).tolist()\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "train_base = datasets.ImageFolder(DATA_DIR, transform=train_transform)\n",
    "val_base = datasets.ImageFolder(DATA_DIR, transform=eval_transform)\n",
    "test_base = datasets.ImageFolder(DATA_DIR, transform=eval_transform)\n",
    "\n",
    "train_dataset = Subset(train_base, train_indices)\n",
    "val_dataset = Subset(val_base, val_indices)\n",
    "test_dataset = Subset(test_base, test_indices)\n",
    "\n",
    "pin_mem = torch.cuda.is_available()\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "\n",
    "print('Classes:', class_names)\n",
    "print(f'Train/Val/Test: {len(train_dataset)}/{len(val_dataset)}/{len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d50905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Models: CNN baseline, CNN+Caps, CNN+CapsGNN\n",
    "# ---------------------------\n",
    "def squash(x, dim=-1, eps=1e-8):\n",
    "    norm_sq = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "    scale = norm_sq / (1.0 + norm_sq)\n",
    "    norm = torch.sqrt(norm_sq + eps)\n",
    "    return scale * (x / norm)\n",
    "\n",
    "\n",
    "class PrimaryCapsules(nn.Module):\n",
    "    def __init__(self, in_channels, num_capsules=8, caps_dim=16, kernel_size=1, stride=1):\n",
    "        super().__init__()\n",
    "        self.num_capsules = num_capsules\n",
    "        self.caps_dim = caps_dim\n",
    "        self.conv = nn.Conv2d(in_channels, num_capsules * caps_dim, kernel_size=kernel_size, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        b, _, h, w = out.shape\n",
    "        out = out.view(b, self.num_capsules, self.caps_dim, h, w)\n",
    "        out = out.permute(0, 3, 4, 1, 2).contiguous()\n",
    "        out = out.view(b, h * w * self.num_capsules, self.caps_dim)\n",
    "        return squash(out)\n",
    "\n",
    "\n",
    "def reduce_capsule_nodes(capsules, max_nodes=128):\n",
    "    # capsules: [B, N, D]\n",
    "    b, n, d = capsules.shape\n",
    "    if n <= max_nodes:\n",
    "        return capsules\n",
    "    pooled = F.adaptive_avg_pool1d(capsules.transpose(1, 2), max_nodes).transpose(1, 2)\n",
    "    return pooled\n",
    "\n",
    "\n",
    "def build_knn_graph(capsules, k=8):\n",
    "    \"\"\"\n",
    "    capsules: [B, N, D]\n",
    "    returns adjacency: [B, N, N] (row-normalized)\n",
    "    \"\"\"\n",
    "    b, n, _ = capsules.shape\n",
    "    x = F.normalize(capsules, p=2, dim=-1)\n",
    "    sim = torch.bmm(x, x.transpose(1, 2))\n",
    "\n",
    "    k_eff = min(k, n)\n",
    "    topk_vals, topk_idx = torch.topk(sim, k=k_eff, dim=-1)\n",
    "\n",
    "    adj = torch.zeros_like(sim)\n",
    "    adj.scatter_(dim=-1, index=topk_idx, src=F.relu(topk_vals))\n",
    "\n",
    "    eye = torch.eye(n, device=capsules.device).unsqueeze(0).expand(b, -1, -1)\n",
    "    adj = adj + eye\n",
    "    row_sum = adj.sum(dim=-1, keepdim=True).clamp_min(1e-8)\n",
    "    return adj / row_sum\n",
    "\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.linear(x)\n",
    "        h = torch.bmm(adj, h)\n",
    "\n",
    "        b, n, d = h.shape\n",
    "        h = self.bn(h.reshape(b * n, d)).reshape(b, n, d)\n",
    "        h = F.relu(h)\n",
    "        return self.dropout(h)\n",
    "\n",
    "\n",
    "class ResNet18Backbone(nn.Module):\n",
    "    def __init__(self, pretrained=True, freeze_early_layers=True):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        base = models.resnet18(weights=weights)\n",
    "        self.features = nn.Sequential(*list(base.children())[:-2])  # [B, 512, 7, 7]\n",
    "\n",
    "        if freeze_early_layers:\n",
    "            for idx, module in enumerate(self.features):\n",
    "                if idx < 6:  # freeze up to layer2\n",
    "                    for param in module.parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        emb = self.pool(feat).flatten(1)\n",
    "        return self.classifier(emb)\n",
    "\n",
    "\n",
    "class CNNCapsClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, max_caps_nodes=128):\n",
    "        super().__init__()\n",
    "        self.max_caps_nodes = max_caps_nodes\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.primary_caps = PrimaryCapsules(in_channels=512, num_capsules=8, caps_dim=16, kernel_size=1, stride=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        caps = self.primary_caps(feat)\n",
    "        caps = reduce_capsule_nodes(caps, max_nodes=self.max_caps_nodes)\n",
    "        emb = caps.mean(dim=1)\n",
    "        return self.classifier(emb)\n",
    "\n",
    "\n",
    "class CNNCapsGNN(nn.Module):\n",
    "    def __init__(self, num_classes, k_neighbors=8, max_caps_nodes=128):\n",
    "        super().__init__()\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.max_caps_nodes = max_caps_nodes\n",
    "\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.primary_caps = PrimaryCapsules(in_channels=512, num_capsules=8, caps_dim=16, kernel_size=1, stride=1)\n",
    "\n",
    "        self.gnn1 = GraphConv(16, 32, dropout=0.15)\n",
    "        self.gnn2 = GraphConv(32, 32, dropout=0.15)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        caps = self.primary_caps(feat)\n",
    "        caps = reduce_capsule_nodes(caps, max_nodes=self.max_caps_nodes)\n",
    "\n",
    "        adj = build_knn_graph(caps, k=self.k_neighbors)\n",
    "        h = self.gnn1(caps, adj)\n",
    "        h = self.gnn2(h, adj)\n",
    "\n",
    "        graph_emb = h.mean(dim=1)\n",
    "        return self.classifier(graph_emb)\n",
    "\n",
    "\n",
    "model_factories = {\n",
    "    'CNN only': lambda: CNNBaseline(num_classes=num_classes),\n",
    "    'CNN + Capsules': lambda: CNNCapsClassifier(num_classes=num_classes, max_caps_nodes=MAX_CAPS_NODES),\n",
    "    'CNN + CapsGNN': lambda: CNNCapsGNN(num_classes=num_classes, k_neighbors=K_NEIGHBORS, max_caps_nodes=MAX_CAPS_NODES),\n",
    "}\n",
    "\n",
    "print('Ablation models:', list(model_factories.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca09b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Train / Eval utilities + Ablation study\n",
    "# ---------------------------\n",
    "def run_epoch(model, loader, criterion, optimizer=None):\n",
    "    train_mode = optimizer is not None\n",
    "    model.train() if train_mode else model.eval()\n",
    "\n",
    "    all_preds, all_targets = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(loader, leave=False):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train_mode):\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            if train_mode:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_targets.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    avg_loss = running_loss / max(len(loader), 1)\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def train_single_model(model_name, model_factory):\n",
    "    model = model_factory().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    save_path = f\"best_{model_name.lower().replace(' ', '_').replace('+', 'plus')}.pth\"\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer=optimizer)\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer=None)\n",
    "\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"[{model_name}] Epoch {epoch:02d}/{EPOCHS} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc * 100:.2f}% | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc * 100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        if val_acc > best_val_acc + MIN_DELTA:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"[{model_name}] Best model saved -> {save_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"[{model_name}] Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'save_path': save_path,\n",
    "        'best_val_acc': best_val_acc,\n",
    "    }\n",
    "\n",
    "\n",
    "ablation_results = []\n",
    "for name, factory in model_factories.items():\n",
    "    print(f\"\\n{'='*25} Training: {name} {'='*25}\")\n",
    "    result = train_single_model(name, factory)\n",
    "    ablation_results.append(result)\n",
    "\n",
    "print('\\nAblation Summary (Validation):')\n",
    "for res in ablation_results:\n",
    "    print(f\"{res['model_name']:<18} | Best Val Acc: {res['best_val_acc'] * 100:.2f}%\")\n",
    "\n",
    "best_run = max(ablation_results, key=lambda x: x['best_val_acc'])\n",
    "print(f\"\\nSelected best model for test/evaluation: {best_run['model_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Test evaluation + confusion matrix + Grad-CAM\n",
    "# ---------------------------\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    preds_all, targets_all = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, leave=False):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds_all.append(logits.argmax(dim=1).cpu().numpy())\n",
    "            targets_all.append(labels.cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    targets_all = np.concatenate(targets_all)\n",
    "    avg_loss = running_loss / max(len(loader), 1)\n",
    "    acc = accuracy_score(targets_all, preds_all)\n",
    "    return avg_loss, acc, targets_all, preds_all\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_results = []\n",
    "for res in ablation_results:\n",
    "    name = res['model_name']\n",
    "    model = model_factories[name]().to(device)\n",
    "    model.load_state_dict(torch.load(res['save_path'], map_location=device))\n",
    "\n",
    "    test_loss, test_acc, y_true, y_pred = evaluate_model(model, test_loader, criterion)\n",
    "    test_results.append({\n",
    "        'model_name': name,\n",
    "        'test_loss': test_loss,\n",
    "        'test_acc': test_acc,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "    })\n",
    "\n",
    "print('\\nAblation Summary (Test):')\n",
    "for tr in test_results:\n",
    "    print(f\"{tr['model_name']:<18} | Test Loss: {tr['test_loss']:.4f} | Test Acc: {tr['test_acc'] * 100:.2f}%\")\n",
    "\n",
    "best_test = max(test_results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\nBest test model: {best_test['model_name']} ({best_test['test_acc'] * 100:.2f}%)\")\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(best_test['y_true'], best_test['y_pred'], target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(best_test['y_true'], best_test['y_pred'])\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_title(f\"Confusion Matrix - {best_test['model_name']}\")\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_xticks(np.arange(len(class_names)))\n",
    "ax.set_yticks(np.arange(len(class_names)))\n",
    "ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        self.fwd_handle = target_layer.register_forward_hook(self._forward_hook)\n",
    "        self.bwd_handle = target_layer.register_full_backward_hook(self._backward_hook)\n",
    "\n",
    "    def _forward_hook(self, module, inputs, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def _backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def generate(self, x, class_idx=None):\n",
    "        self.model.eval()\n",
    "        logits = self.model(x)\n",
    "\n",
    "        if class_idx is None:\n",
    "            class_idx = logits.argmax(dim=1).item()\n",
    "\n",
    "        score = logits[:, class_idx]\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        score.backward(retain_graph=True)\n",
    "\n",
    "        grads = self.gradients\n",
    "        acts = self.activations\n",
    "\n",
    "        weights = grads.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * acts).sum(dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        cam = F.interpolate(cam, size=(IMG_SIZE, IMG_SIZE), mode='bilinear', align_corners=False)\n",
    "\n",
    "        cam = cam.squeeze().detach().cpu().numpy()\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        return cam, class_idx\n",
    "\n",
    "    def close(self):\n",
    "        self.fwd_handle.remove()\n",
    "        self.bwd_handle.remove()\n",
    "\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=img_tensor.device).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=img_tensor.device).view(3, 1, 1)\n",
    "    img = img_tensor * std + mean\n",
    "    return img.clamp(0, 1)\n",
    "\n",
    "\n",
    "best_model_name = best_test['model_name']\n",
    "best_model = model_factories[best_model_name]().to(device)\n",
    "best_model.load_state_dict(torch.load(next(r['save_path'] for r in ablation_results if r['model_name'] == best_model_name), map_location=device))\n",
    "\n",
    "sample_img, sample_label = test_dataset[0]\n",
    "input_tensor = sample_img.unsqueeze(0).to(device)\n",
    "\n",
    "target_layer = best_model.backbone.features[-1]\n",
    "grad_cam = GradCAM(best_model, target_layer)\n",
    "cam, pred_idx = grad_cam.generate(input_tensor)\n",
    "grad_cam.close()\n",
    "\n",
    "img_np = denormalize(sample_img.to(device)).permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_np)\n",
    "plt.title(f\"Input\\nTrue: {class_names[sample_label]}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cam, cmap='jet')\n",
    "plt.title('Grad-CAM Heatmap')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_np)\n",
    "plt.imshow(cam, cmap='jet', alpha=0.45)\n",
    "plt.title(f\"Overlay\\nPred: {class_names[pred_idx]}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
