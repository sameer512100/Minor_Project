{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc236d59",
   "metadata": {},
   "source": [
    "# CNN + Capsules + Learnable Edge-Gated CapsGNN for GI Image Classification\n",
    "\n",
    "This notebook extends the previous pipeline with the novelty:\n",
    "- **Learnable Edge-Gated Capsule Graph (k-NN + Edge Gate MLP)**\n",
    "\n",
    "Models compared in ablation:\n",
    "1. CNN only\n",
    "2. CNN + Capsules\n",
    "3. CNN + CapsGNN (fixed cosine-kNN graph)\n",
    "4. CNN + Caps + EdgeGatedGNN (**novelty**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482b6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch torchvision torchaudio\n",
    "!pip install -q numpy tqdm scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b517909c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import json\n",
    "import zipfile\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 15\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "K_NEIGHBORS = 8\n",
    "MAX_CAPS_NODES = 128\n",
    "EXPECTED_NUM_CLASSES = 8\n",
    "EARLY_STOPPING_PATIENCE = 7\n",
    "MIN_DELTA = 1e-4\n",
    "NUM_WORKERS = min(4, os.cpu_count() or 0)\n",
    "\n",
    "kaggle_matches = glob.glob('/kaggle/input/**/kvasir-dataset-v2', recursive=True)\n",
    "kaggle_auto = kaggle_matches[0] if len(kaggle_matches) else None\n",
    "\n",
    "DATA_CANDIDATES = [\n",
    "    os.path.join(os.getcwd(), 'kvasir-dataset-v2'),\n",
    "    r'c:/Users/sayye/OneDrive/Desktop/Minor_Project/kvasir-dataset-v2',\n",
    "    r'/kaggle/input/datasets/sameer512100/kvasir-minor-project/kvasir-dataset-v2',\n",
    "    r'/kaggle/input/kvasir-dataset-v2',\n",
    "    kaggle_auto,\n",
    "    '/kaggle/working/kvasir-dataset-v2'\n",
    " ]\n",
    "DATA_DIR = next((p for p in DATA_CANDIDATES if p and os.path.isdir(p)), None)\n",
    "if DATA_DIR is None:\n",
    "    raise FileNotFoundError('kvasir-dataset-v2 not found. Update DATA_CANDIDATES in this cell.')\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(os.getcwd(), 'checkpoints_edge_gated')\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print('DATA_DIR:', DATA_DIR)\n",
    "print('Checkpoint dir:', CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56408ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.10, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "base_dataset = datasets.ImageFolder(DATA_DIR)\n",
    "class_names = base_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "if num_classes != EXPECTED_NUM_CLASSES:\n",
    "    raise ValueError(f'Expected {EXPECTED_NUM_CLASSES} classes, found {num_classes}: {class_names}')\n",
    "\n",
    "n_samples = len(base_dataset)\n",
    "train_size = int(0.70 * n_samples)\n",
    "val_size = int(0.15 * n_samples)\n",
    "test_size = n_samples - train_size - val_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "indices = torch.randperm(n_samples, generator=generator).tolist()\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "train_base = datasets.ImageFolder(DATA_DIR, transform=train_transform)\n",
    "val_base = datasets.ImageFolder(DATA_DIR, transform=eval_transform)\n",
    "test_base = datasets.ImageFolder(DATA_DIR, transform=eval_transform)\n",
    "\n",
    "train_dataset = Subset(train_base, train_indices)\n",
    "val_dataset = Subset(val_base, val_indices)\n",
    "test_dataset = Subset(test_base, test_indices)\n",
    "\n",
    "pin_mem = torch.cuda.is_available()\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "\n",
    "print('Classes:', class_names)\n",
    "print(f'Train/Val/Test: {len(train_dataset)}/{len(val_dataset)}/{len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0f34d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, dim=-1, eps=1e-8):\n",
    "    norm_sq = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "    scale = norm_sq / (1.0 + norm_sq)\n",
    "    norm = torch.sqrt(norm_sq + eps)\n",
    "    return scale * (x / norm)\n",
    "\n",
    "class PrimaryCapsules(nn.Module):\n",
    "    def __init__(self, in_channels, num_capsules=8, caps_dim=16, kernel_size=1, stride=1):\n",
    "        super().__init__()\n",
    "        self.num_capsules = num_capsules\n",
    "        self.caps_dim = caps_dim\n",
    "        self.conv = nn.Conv2d(in_channels, num_capsules * caps_dim, kernel_size=kernel_size, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        b, _, h, w = out.shape\n",
    "        out = out.view(b, self.num_capsules, self.caps_dim, h, w)\n",
    "        out = out.permute(0, 3, 4, 1, 2).contiguous()\n",
    "        out = out.view(b, h * w * self.num_capsules, self.caps_dim)\n",
    "        return squash(out)\n",
    "\n",
    "def reduce_capsule_nodes(capsules, max_nodes=128):\n",
    "    b, n, d = capsules.shape\n",
    "    if n <= max_nodes:\n",
    "        return capsules\n",
    "    return F.adaptive_avg_pool1d(capsules.transpose(1, 2), max_nodes).transpose(1, 2)\n",
    "\n",
    "def build_knn_graph_fixed(capsules, k=8):\n",
    "    b, n, _ = capsules.shape\n",
    "    x = F.normalize(capsules, p=2, dim=-1)\n",
    "    sim = torch.bmm(x, x.transpose(1, 2))\n",
    "\n",
    "    k_eff = min(k, n)\n",
    "    topk_vals, topk_idx = torch.topk(sim, k=k_eff, dim=-1)\n",
    "\n",
    "    adj = torch.zeros_like(sim)\n",
    "    adj.scatter_(dim=-1, index=topk_idx, src=F.relu(topk_vals))\n",
    "\n",
    "    eye = torch.eye(n, device=capsules.device).unsqueeze(0).expand(b, -1, -1)\n",
    "    adj = adj + eye\n",
    "    row_sum = adj.sum(dim=-1, keepdim=True).clamp_min(1e-8)\n",
    "    return adj / row_sum\n",
    "\n",
    "class LearnableEdgeGate(nn.Module):\n",
    "    \"\"\"Builds gated k-NN adjacency using Edge Gate MLP.\"\"\"\n",
    "    def __init__(self, node_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        in_dim = 4 * node_dim + 1  # xi, xj, |xi-xj|, xi*xj, cosine(xi,xj)\n",
    "        self.edge_mlp = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, capsules, k=8):\n",
    "        b, n, d = capsules.shape\n",
    "        x_norm = F.normalize(capsules, p=2, dim=-1)\n",
    "        sim = torch.bmm(x_norm, x_norm.transpose(1, 2))\n",
    "\n",
    "        k_eff = min(k, n)\n",
    "        topk_vals, topk_idx = torch.topk(sim, k=k_eff, dim=-1)  # [B, N, K]\n",
    "\n",
    "        xi = capsules.unsqueeze(2).expand(-1, -1, k_eff, -1)  # [B, N, K, D]\n",
    "        idx_exp = topk_idx.unsqueeze(-1).expand(-1, -1, -1, d)\n",
    "\n",
    "        all_nodes = capsules.unsqueeze(1).expand(-1, n, -1, -1)  # [B, N, N, D]\n",
    "        xj = torch.gather(all_nodes, dim=2, index=idx_exp)  # [B, N, K, D]\n",
    "\n",
    "        edge_feat = torch.cat([\n",
    "            xi,\n",
    "            xj,\n",
    "            torch.abs(xi - xj),\n",
    "            xi * xj,\n",
    "            topk_vals.unsqueeze(-1)\n",
    "        ], dim=-1)\n",
    "\n",
    "        gate = torch.sigmoid(self.edge_mlp(edge_feat)).squeeze(-1)  # [B, N, K]\n",
    "        weights = gate * F.relu(topk_vals)\n",
    "\n",
    "        adj = torch.zeros_like(sim)\n",
    "        adj.scatter_(dim=-1, index=topk_idx, src=weights)\n",
    "\n",
    "        eye = torch.eye(n, device=capsules.device).unsqueeze(0).expand(b, -1, -1)\n",
    "        adj = adj + eye\n",
    "        row_sum = adj.sum(dim=-1, keepdim=True).clamp_min(1e-8)\n",
    "        return adj / row_sum\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.linear(x)\n",
    "        h = torch.bmm(adj, h)\n",
    "        b, n, d = h.shape\n",
    "        h = self.bn(h.reshape(b * n, d)).reshape(b, n, d)\n",
    "        h = F.relu(h)\n",
    "        return self.dropout(h)\n",
    "\n",
    "class ResNet18Backbone(nn.Module):\n",
    "    def __init__(self, pretrained=True, freeze_early_layers=True):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        base = models.resnet18(weights=weights)\n",
    "        self.features = nn.Sequential(*list(base.children())[:-2])  # [B, 512, 7, 7]\n",
    "\n",
    "        if freeze_early_layers:\n",
    "            for idx, module in enumerate(self.features):\n",
    "                if idx < 6:\n",
    "                    for p in module.parameters():\n",
    "                        p.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        emb = self.pool(feat).flatten(1)\n",
    "        return self.classifier(emb)\n",
    "\n",
    "class CNNCapsClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, max_caps_nodes=128):\n",
    "        super().__init__()\n",
    "        self.max_caps_nodes = max_caps_nodes\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.primary_caps = PrimaryCapsules(in_channels=512, num_capsules=8, caps_dim=16)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        caps = self.primary_caps(feat)\n",
    "        caps = reduce_capsule_nodes(caps, self.max_caps_nodes)\n",
    "        emb = caps.mean(dim=1)\n",
    "        return self.classifier(emb)\n",
    "\n",
    "class CNNCapsGNN(nn.Module):\n",
    "    def __init__(self, num_classes, k_neighbors=8, max_caps_nodes=128):\n",
    "        super().__init__()\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.max_caps_nodes = max_caps_nodes\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.primary_caps = PrimaryCapsules(in_channels=512, num_capsules=8, caps_dim=16)\n",
    "        self.gnn1 = GraphConv(16, 32, dropout=0.15)\n",
    "        self.gnn2 = GraphConv(32, 32, dropout=0.15)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        caps = self.primary_caps(feat)\n",
    "        caps = reduce_capsule_nodes(caps, self.max_caps_nodes)\n",
    "        adj = build_knn_graph_fixed(caps, k=self.k_neighbors)\n",
    "        h = self.gnn1(caps, adj)\n",
    "        h = self.gnn2(h, adj)\n",
    "        return self.classifier(h.mean(dim=1))\n",
    "\n",
    "class CNNCapsEdgeGNN(nn.Module):\n",
    "    def __init__(self, num_classes, k_neighbors=8, max_caps_nodes=128):\n",
    "        super().__init__()\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.max_caps_nodes = max_caps_nodes\n",
    "\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.primary_caps = PrimaryCapsules(in_channels=512, num_capsules=8, caps_dim=16)\n",
    "\n",
    "        self.edge_gate_builder = LearnableEdgeGate(node_dim=16, hidden_dim=64)\n",
    "        self.gnn1 = GraphConv(16, 32, dropout=0.15)\n",
    "        self.gnn2 = GraphConv(32, 32, dropout=0.15)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        caps = self.primary_caps(feat)\n",
    "        caps = reduce_capsule_nodes(caps, self.max_caps_nodes)\n",
    "\n",
    "        adj = self.edge_gate_builder(caps, k=self.k_neighbors)\n",
    "        h = self.gnn1(caps, adj)\n",
    "        h = self.gnn2(h, adj)\n",
    "        return self.classifier(h.mean(dim=1))\n",
    "\n",
    "model_factories = {\n",
    "    'CNN only': lambda: CNNBaseline(num_classes=num_classes),\n",
    "    'CNN + Capsules': lambda: CNNCapsClassifier(num_classes=num_classes, max_caps_nodes=MAX_CAPS_NODES),\n",
    "    'CNN + CapsGNN': lambda: CNNCapsGNN(num_classes=num_classes, k_neighbors=K_NEIGHBORS, max_caps_nodes=MAX_CAPS_NODES),\n",
    "    'CNN + Caps + EdgeGatedGNN': lambda: CNNCapsEdgeGNN(num_classes=num_classes, k_neighbors=K_NEIGHBORS, max_caps_nodes=MAX_CAPS_NODES),\n",
    "}\n",
    "print('Ablation models:', list(model_factories.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70788eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backup_checkpoints(checkpoint_dir, backup_zip_path):\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        return\n",
    "    with zipfile.ZipFile(backup_zip_path, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "        for root, _, files in os.walk(checkpoint_dir):\n",
    "            for fname in files:\n",
    "                if fname.endswith('.pth') or fname.endswith('.json'):\n",
    "                    fpath = os.path.join(root, fname)\n",
    "                    arcname = os.path.relpath(fpath, checkpoint_dir)\n",
    "                    zf.write(fpath, arcname=arcname)\n",
    "\n",
    "def run_epoch(model, loader, criterion, optimizer=None):\n",
    "    train_mode = optimizer is not None\n",
    "    model.train() if train_mode else model.eval()\n",
    "\n",
    "    all_preds, all_targets = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(loader, leave=False):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train_mode):\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            if train_mode:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_targets.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    avg_loss = running_loss / max(len(loader), 1)\n",
    "    return avg_loss, acc\n",
    "\n",
    "def plot_training_history(model_name, history):\n",
    "    epochs = history['epochs']\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history['train_loss'], marker='o', label='Train Loss')\n",
    "    plt.plot(epochs, history['val_loss'], marker='o', label='Val Loss')\n",
    "    plt.title(f'Loss Curves - {model_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, np.array(history['train_acc']) * 100, marker='o', label='Train Acc')\n",
    "    plt.plot(epochs, np.array(history['val_acc']) * 100, marker='o', label='Val Acc')\n",
    "    plt.title(f'Accuracy Curves - {model_name}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy (%)')\n",
    "    plt.grid(alpha=0.25)\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def train_single_model(model_name, model_factory):\n",
    "    model = model_factory().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    best_epoch = 0\n",
    "    save_file = f\"best_{model_name.lower().replace(' ', '_').replace('+', 'plus')}.pth\"\n",
    "    save_path = os.path.join(CHECKPOINT_DIR, save_file)\n",
    "\n",
    "    history = {\n",
    "        'epochs': [],\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': []\n",
    "    }\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer=optimizer)\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer=None)\n",
    "\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        history['epochs'].append(epoch)\n",
    "        history['train_loss'].append(float(train_loss))\n",
    "        history['train_acc'].append(float(train_acc))\n",
    "        history['val_loss'].append(float(val_loss))\n",
    "        history['val_acc'].append(float(val_acc))\n",
    "\n",
    "        print(f\"[{model_name}] Epoch {epoch:02d}/{EPOCHS} | Train Loss: {train_loss:.4f} | Train Acc: {train_acc * 100:.2f}% | Val Loss: {val_loss:.4f} | Val Acc: {val_acc * 100:.2f}%\")\n",
    "\n",
    "        if val_acc > best_val_acc + MIN_DELTA:\n",
    "            best_val_acc = val_acc\n",
    "            best_epoch = epoch\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"[{model_name}] Best model saved -> {save_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"[{model_name}] Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    plot_training_history(model_name, history)\n",
    "\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'save_path': save_path,\n",
    "        'best_val_acc': float(best_val_acc),\n",
    "        'best_epoch': int(best_epoch),\n",
    "        'history': history\n",
    "    }\n",
    "\n",
    "ablation_results = []\n",
    "for name, factory in model_factories.items():\n",
    "    print(f\"\\n{'='*24} Training: {name} {'='*24}\")\n",
    "    result = train_single_model(name, factory)\n",
    "    ablation_results.append(result)\n",
    "\n",
    "print('\\nAblation Summary (Validation):')\n",
    "for res in ablation_results:\n",
    "    print(f\"{res['model_name']:<30} | Best Val Acc: {res['best_val_acc'] * 100:.2f}% | Best Epoch: {res['best_epoch']}\")\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "names = [r['model_name'] for r in ablation_results]\n",
    "val_accs = [r['best_val_acc'] * 100 for r in ablation_results]\n",
    "bars = plt.bar(names, val_accs)\n",
    "plt.ylabel('Best Validation Accuracy (%)')\n",
    "plt.title('Validation Accuracy Comparison Across Models')\n",
    "plt.xticks(rotation=20, ha='right')\n",
    "plt.grid(axis='y', alpha=0.25)\n",
    "for b, v in zip(bars, val_accs):\n",
    "    plt.text(b.get_x() + b.get_width()/2, b.get_height() + 0.2, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_run = max(ablation_results, key=lambda x: x['best_val_acc'])\n",
    "print(f\"\\nSelected best model for test/eval: {best_run['model_name']}\")\n",
    "\n",
    "run_manifest_path = os.path.join(CHECKPOINT_DIR, 'ablation_results.json')\n",
    "with open(run_manifest_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(ablation_results, f, indent=2)\n",
    "\n",
    "backup_zip_path = os.path.join(os.getcwd(), 'checkpoints_edge_gated_backup.zip')\n",
    "backup_checkpoints(CHECKPOINT_DIR, backup_zip_path)\n",
    "print(f\"Checkpoint backup zip created: {backup_zip_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d9f5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    preds_all, targets_all = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, leave=False):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds_all.append(logits.argmax(dim=1).cpu().numpy())\n",
    "            targets_all.append(labels.cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    targets_all = np.concatenate(targets_all)\n",
    "    avg_loss = running_loss / max(len(loader), 1)\n",
    "    acc = accuracy_score(targets_all, preds_all)\n",
    "    return avg_loss, acc, targets_all, preds_all\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_results = []\n",
    "\n",
    "for res in ablation_results:\n",
    "    name = res['model_name']\n",
    "    ckpt = res['save_path']\n",
    "    if not os.path.exists(ckpt):\n",
    "        print(f'Skipping {name}: checkpoint not found at {ckpt}')\n",
    "        continue\n",
    "\n",
    "    model = model_factories[name]().to(device)\n",
    "    model.load_state_dict(torch.load(ckpt, map_location=device))\n",
    "\n",
    "    test_loss, test_acc, y_true, y_pred = evaluate_model(model, test_loader, criterion)\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True, zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    test_results.append({\n",
    "        'model_name': name,\n",
    "        'test_loss': float(test_loss),\n",
    "        'test_acc': float(test_acc),\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "        'report': report,\n",
    "        'confusion_matrix': cm.tolist()\n",
    "    })\n",
    "\n",
    "if len(test_results) == 0:\n",
    "    raise RuntimeError('No test results found. Run the training cell first.')\n",
    "\n",
    "print('\\nAblation Summary (Test):')\n",
    "for tr in test_results:\n",
    "    macro_f1 = tr['report']['macro avg']['f1-score'] * 100\n",
    "    print(f\"{tr['model_name']:<30} | Test Loss: {tr['test_loss']:.4f} | Test Acc: {tr['test_acc'] * 100:.2f}% | Macro-F1: {macro_f1:.2f}%\")\n",
    "\n",
    "for tr in test_results:\n",
    "    model_name = tr['model_name']\n",
    "    y_true = tr['y_true']\n",
    "    y_pred = tr['y_pred']\n",
    "    report = tr['report']\n",
    "    cm = np.array(tr['confusion_matrix'])\n",
    "\n",
    "    print(f\"\\n{'='*12} Detailed Report: {model_name} {'='*12}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, zero_division=0))\n",
    "\n",
    "    per_class_f1 = [report[c]['f1-score'] * 100 for c in class_names]\n",
    "\n",
    "    plt.figure(figsize=(16, 4.5))\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    im = plt.imshow(cm, cmap='Blues')\n",
    "    plt.title(f'Confusion Matrix\\n{model_name}')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(np.arange(len(class_names)), class_names, rotation=45, ha='right')\n",
    "    plt.yticks(np.arange(len(class_names)), class_names)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, cm[i, j], ha='center', va='center', color='black', fontsize=7)\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    bars = plt.bar(class_names, per_class_f1)\n",
    "    plt.title(f'Per-Class F1 (%)\\n{model_name}')\n",
    "    plt.ylabel('F1-score (%)')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.25)\n",
    "    for b, v in zip(bars, per_class_f1):\n",
    "        plt.text(b.get_x() + b.get_width()/2, v + 0.5, f'{v:.1f}', ha='center', va='bottom', fontsize=7)\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    metrics = ['Accuracy', 'Macro Precision', 'Macro Recall', 'Macro F1']\n",
    "    values = [\n",
    "        tr['test_acc'] * 100,\n",
    "        report['macro avg']['precision'] * 100,\n",
    "        report['macro avg']['recall'] * 100,\n",
    "        report['macro avg']['f1-score'] * 100\n",
    "    ]\n",
    "    bars = plt.bar(metrics, values)\n",
    "    plt.title(f'Overall Metrics (%)\\n{model_name}')\n",
    "    plt.ylim(0, 100)\n",
    "    plt.xticks(rotation=20, ha='right')\n",
    "    plt.grid(axis='y', alpha=0.25)\n",
    "    for b, v in zip(bars, values):\n",
    "        plt.text(b.get_x() + b.get_width()/2, v + 0.5, f'{v:.1f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "test_summary_path = os.path.join(CHECKPOINT_DIR, 'test_results_detailed.json')\n",
    "with open(test_summary_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(test_results, f, indent=2)\n",
    "print(f'Detailed test results saved at: {test_summary_path}')\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "names = [r['model_name'] for r in test_results]\n",
    "accs = [r['test_acc'] * 100 for r in test_results]\n",
    "macro_f1s = [r['report']['macro avg']['f1-score'] * 100 for r in test_results]\n",
    "\n",
    "x = np.arange(len(names))\n",
    "w = 0.36\n",
    "plt.bar(x - w/2, accs, width=w, label='Test Accuracy (%)')\n",
    "plt.bar(x + w/2, macro_f1s, width=w, label='Macro-F1 (%)')\n",
    "plt.xticks(x, names, rotation=20, ha='right')\n",
    "plt.ylabel('Score (%)')\n",
    "plt.title('Final Model Comparison on Test Set')\n",
    "plt.grid(axis='y', alpha=0.25)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "best_test = max(test_results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\nBest test model: {best_test['model_name']} ({best_test['test_acc'] * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b303b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export trained artifacts for download/reuse (Kaggle-friendly)\n",
    "import shutil\n",
    "from IPython.display import FileLink, display\n",
    "\n",
    "EXPORT_DIR = os.path.join(os.getcwd(), 'model_export_edge_gated')\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "# Copy checkpoint files + metadata\n",
    "copied = []\n",
    "for item in ablation_results:\n",
    "    src = item.get('save_path', '')\n",
    "    if src and os.path.exists(src):\n",
    "        dst = os.path.join(EXPORT_DIR, os.path.basename(src))\n",
    "        shutil.copy2(src, dst)\n",
    "        copied.append(dst)\n",
    "\n",
    "for meta_name in ['ablation_results.json', 'test_results_detailed.json']:\n",
    "    meta_src = os.path.join(CHECKPOINT_DIR, meta_name)\n",
    "    if os.path.exists(meta_src):\n",
    "        shutil.copy2(meta_src, os.path.join(EXPORT_DIR, meta_name))\n",
    "\n",
    "export_zip = os.path.join(os.getcwd(), 'edge_gated_model_export.zip')\n",
    "with zipfile.ZipFile(export_zip, mode='w', compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    for root, _, files in os.walk(EXPORT_DIR):\n",
    "        for fname in files:\n",
    "            fpath = os.path.join(root, fname)\n",
    "            arcname = os.path.relpath(fpath, EXPORT_DIR)\n",
    "            zf.write(fpath, arcname=arcname)\n",
    "\n",
    "print('Exported checkpoint files:', len(copied))\n",
    "for p in copied:\n",
    "    print('-', p)\n",
    "\n",
    "print('\\nDownload this zip from Kaggle Files panel:')\n",
    "print(export_zip)\n",
    "display(FileLink(export_zip))\n",
    "\n",
    "# Optional helper snippet for future sessions\n",
    "print('\\nFuture load example:')\n",
    "print(\"model = CNNCapsEdgeGNN(num_classes=8, k_neighbors=8, max_caps_nodes=128).to(device)\")\n",
    "print(\"model.load_state_dict(torch.load('/kaggle/input/YOUR_DATASET/best_cnn_plus_caps_plus_edgegatedgnn.pth', map_location=device))\")\n",
    "print(\"model.eval()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dbd11",
   "metadata": {},
   "source": [
    "## Notes for Paper Write-up\n",
    "\n",
    "- Novelty module: **Learnable Edge-Gated Capsule Graph (k-NN + Edge Gate MLP)**\n",
    "- Compare against fixed-edge CapsGNN to isolate novelty gain.\n",
    "- Report Accuracy + Macro-F1 and add qualitative edge-gate interpretation plots in future iteration."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
