{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41196d3f",
   "metadata": {},
   "source": [
    "# CNN + CapsGNN for GI Image Classification\n",
    "\n",
    "This notebook implements a hybrid model:\n",
    "- **CNN backbone** for local feature extraction\n",
    "- **Primary Capsules** for part-whole representation\n",
    "- **Graph Neural Network (CapsGNN)** over capsule nodes for relational reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d372e9b-1570-4e8e-85fd-70a8568a632c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install numpy tqdm scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e186d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------------------------\n",
    "# Reproducibility + Device\n",
    "# ---------------------------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device:', device)\n",
    "\n",
    "# ---------------------------\n",
    "# Paths + Hyperparameters\n",
    "# ---------------------------\n",
    "# Set this to your Kvasir dataset root containing class folders\n",
    "DATA_DIR = r\"kvasir-dataset-v2\"\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 15\n",
    "LR = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "K_NEIGHBORS = 8\n",
    "MAX_CAPS_NODES = 128\n",
    "EXPECTED_NUM_CLASSES = 8\n",
    "EARLY_STOPPING_PATIENCE = 7\n",
    "MIN_DELTA = 1e-4\n",
    "NUM_WORKERS = min(4, os.cpu_count() or 0)\n",
    "\n",
    "CHECKPOINT_DIR = os.path.join(os.getcwd(), 'checkpoints')\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "print('Checkpoint dir:', CHECKPOINT_DIR)\n",
    "\n",
    "if not os.path.isdir(DATA_DIR):\n",
    "    raise FileNotFoundError(f\"DATA_DIR not found: {DATA_DIR}. Please update DATA_DIR in this cell.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dc3a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['dyed-lifted-polyps', 'dyed-resection-margins', 'esophagitis', 'normal-cecum', 'normal-pylorus', 'normal-z-line', 'polyps', 'ulcerative-colitis']\n",
      "Train/Val/Test: 5600/1200/1200\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Dataset + DataLoaders (with augmentation)\n",
    "# ---------------------------\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.15, contrast=0.15, saturation=0.10, hue=0.02),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "base_dataset = datasets.ImageFolder(DATA_DIR)\n",
    "class_names = base_dataset.classes\n",
    "num_classes = len(class_names)\n",
    "\n",
    "if num_classes != EXPECTED_NUM_CLASSES:\n",
    "    raise ValueError(f\"Expected {EXPECTED_NUM_CLASSES} classes, but found {num_classes}: {class_names}\")\n",
    "\n",
    "n_samples = len(base_dataset)\n",
    "train_size = int(0.70 * n_samples)\n",
    "val_size = int(0.15 * n_samples)\n",
    "test_size = n_samples - train_size - val_size\n",
    "\n",
    "generator = torch.Generator().manual_seed(SEED)\n",
    "indices = torch.randperm(n_samples, generator=generator).tolist()\n",
    "\n",
    "train_indices = indices[:train_size]\n",
    "val_indices = indices[train_size:train_size + val_size]\n",
    "test_indices = indices[train_size + val_size:]\n",
    "\n",
    "train_base = datasets.ImageFolder(DATA_DIR, transform=train_transform)\n",
    "val_base = datasets.ImageFolder(DATA_DIR, transform=eval_transform)\n",
    "test_base = datasets.ImageFolder(DATA_DIR, transform=eval_transform)\n",
    "\n",
    "train_dataset = Subset(train_base, train_indices)\n",
    "val_dataset = Subset(val_base, val_indices)\n",
    "test_dataset = Subset(test_base, test_indices)\n",
    "\n",
    "pin_mem = torch.cuda.is_available()\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=pin_mem)\n",
    "\n",
    "print('Classes:', class_names)\n",
    "print(f'Train/Val/Test: {len(train_dataset)}/{len(val_dataset)}/{len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d50905d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ablation models: ['CNN only', 'CNN + Capsules', 'CNN + CapsGNN']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Models: CNN baseline, CNN+Caps, CNN+CapsGNN\n",
    "# ---------------------------\n",
    "def squash(x, dim=-1, eps=1e-8):\n",
    "    norm_sq = (x ** 2).sum(dim=dim, keepdim=True)\n",
    "    scale = norm_sq / (1.0 + norm_sq)\n",
    "    norm = torch.sqrt(norm_sq + eps)\n",
    "    return scale * (x / norm)\n",
    "\n",
    "\n",
    "class PrimaryCapsules(nn.Module):\n",
    "    def __init__(self, in_channels, num_capsules=8, caps_dim=16, kernel_size=1, stride=1):\n",
    "        super().__init__()\n",
    "        self.num_capsules = num_capsules\n",
    "        self.caps_dim = caps_dim\n",
    "        self.conv = nn.Conv2d(in_channels, num_capsules * caps_dim, kernel_size=kernel_size, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        b, _, h, w = out.shape\n",
    "        out = out.view(b, self.num_capsules, self.caps_dim, h, w)\n",
    "        out = out.permute(0, 3, 4, 1, 2).contiguous()\n",
    "        out = out.view(b, h * w * self.num_capsules, self.caps_dim)\n",
    "        return squash(out)\n",
    "\n",
    "\n",
    "def reduce_capsule_nodes(capsules, max_nodes=128):\n",
    "    # capsules: [B, N, D]\n",
    "    b, n, d = capsules.shape\n",
    "    if n <= max_nodes:\n",
    "        return capsules\n",
    "    pooled = F.adaptive_avg_pool1d(capsules.transpose(1, 2), max_nodes).transpose(1, 2)\n",
    "    return pooled\n",
    "\n",
    "\n",
    "def build_knn_graph(capsules, k=8):\n",
    "    \"\"\"\n",
    "    capsules: [B, N, D]\n",
    "    returns adjacency: [B, N, N] (row-normalized)\n",
    "    \"\"\"\n",
    "    b, n, _ = capsules.shape\n",
    "    x = F.normalize(capsules, p=2, dim=-1)\n",
    "    sim = torch.bmm(x, x.transpose(1, 2))\n",
    "\n",
    "    k_eff = min(k, n)\n",
    "    topk_vals, topk_idx = torch.topk(sim, k=k_eff, dim=-1)\n",
    "\n",
    "    adj = torch.zeros_like(sim)\n",
    "    adj.scatter_(dim=-1, index=topk_idx, src=F.relu(topk_vals))\n",
    "\n",
    "    eye = torch.eye(n, device=capsules.device).unsqueeze(0).expand(b, -1, -1)\n",
    "    adj = adj + eye\n",
    "    row_sum = adj.sum(dim=-1, keepdim=True).clamp_min(1e-8)\n",
    "    return adj / row_sum\n",
    "\n",
    "\n",
    "class GraphConv(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.bn = nn.BatchNorm1d(out_dim)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        h = self.linear(x)\n",
    "        h = torch.bmm(adj, h)\n",
    "\n",
    "        b, n, d = h.shape\n",
    "        h = self.bn(h.reshape(b * n, d)).reshape(b, n, d)\n",
    "        h = F.relu(h)\n",
    "        return self.dropout(h)\n",
    "\n",
    "\n",
    "class ResNet18Backbone(nn.Module):\n",
    "    def __init__(self, pretrained=True, freeze_early_layers=True):\n",
    "        super().__init__()\n",
    "        weights = ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "        base = models.resnet18(weights=weights)\n",
    "        self.features = nn.Sequential(*list(base.children())[:-2])  # [B, 512, 7, 7]\n",
    "\n",
    "        if freeze_early_layers:\n",
    "            for idx, module in enumerate(self.features):\n",
    "                if idx < 6:  # freeze up to layer2\n",
    "                    for param in module.parameters():\n",
    "                        param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "\n",
    "\n",
    "class CNNBaseline(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        emb = self.pool(feat).flatten(1)\n",
    "        return self.classifier(emb)\n",
    "\n",
    "\n",
    "class CNNCapsClassifier(nn.Module):\n",
    "    def __init__(self, num_classes, max_caps_nodes=128):\n",
    "        super().__init__()\n",
    "        self.max_caps_nodes = max_caps_nodes\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.primary_caps = PrimaryCapsules(in_channels=512, num_capsules=8, caps_dim=16, kernel_size=1, stride=1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(16, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        caps = self.primary_caps(feat)\n",
    "        caps = reduce_capsule_nodes(caps, max_nodes=self.max_caps_nodes)\n",
    "        emb = caps.mean(dim=1)\n",
    "        return self.classifier(emb)\n",
    "\n",
    "\n",
    "class CNNCapsGNN(nn.Module):\n",
    "    def __init__(self, num_classes, k_neighbors=8, max_caps_nodes=128):\n",
    "        super().__init__()\n",
    "        self.k_neighbors = k_neighbors\n",
    "        self.max_caps_nodes = max_caps_nodes\n",
    "\n",
    "        self.backbone = ResNet18Backbone(pretrained=True, freeze_early_layers=True)\n",
    "        self.primary_caps = PrimaryCapsules(in_channels=512, num_capsules=8, caps_dim=16, kernel_size=1, stride=1)\n",
    "\n",
    "        self.gnn1 = GraphConv(16, 32, dropout=0.15)\n",
    "        self.gnn2 = GraphConv(32, 32, dropout=0.15)\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        feat = self.backbone(x)\n",
    "        caps = self.primary_caps(feat)\n",
    "        caps = reduce_capsule_nodes(caps, max_nodes=self.max_caps_nodes)\n",
    "\n",
    "        adj = build_knn_graph(caps, k=self.k_neighbors)\n",
    "        h = self.gnn1(caps, adj)\n",
    "        h = self.gnn2(h, adj)\n",
    "\n",
    "        graph_emb = h.mean(dim=1)\n",
    "        return self.classifier(graph_emb)\n",
    "\n",
    "\n",
    "model_factories = {\n",
    "    'CNN only': lambda: CNNBaseline(num_classes=num_classes),\n",
    "    'CNN + Capsules': lambda: CNNCapsClassifier(num_classes=num_classes, max_caps_nodes=MAX_CAPS_NODES),\n",
    "    'CNN + CapsGNN': lambda: CNNCapsGNN(num_classes=num_classes, k_neighbors=K_NEIGHBORS, max_caps_nodes=MAX_CAPS_NODES),\n",
    "}\n",
    "\n",
    "print('Ablation models:', list(model_factories.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca09b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================= Training: CNN only =========================\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\sayye/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████| 44.7M/44.7M [00:02<00:00, 16.9MB/s]\n",
      "                                                                                                             "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 80\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, factory \u001b[38;5;129;01min\u001b[39;00m model_factories\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m25\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 80\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfactory\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     81\u001b[0m     ablation_results\u001b[38;5;241m.\u001b[39mappend(result)\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAblation Summary (Validation):\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 47\u001b[0m, in \u001b[0;36mtrain_single_model\u001b[1;34m(model_name, model_factory)\u001b[0m\n\u001b[0;32m     44\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplus\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 47\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     val_loss, val_acc \u001b[38;5;241m=\u001b[39m run_epoch(model, val_loader, criterion, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     50\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep(val_acc)\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(model, loader, criterion, optimizer)\u001b[0m\n\u001b[0;32m     13\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(train_mode):\n\u001b[1;32m---> 16\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(logits, labels)\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m train_mode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[6], line 99\u001b[0m, in \u001b[0;36mCNNBaseline.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 99\u001b[0m     feat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool(feat)\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(emb)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[6], line 88\u001b[0m, in \u001b[0;36mResNet18Backbone.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:253\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\container.py:253\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;124;03mRuns the forward pass.\u001b[39;00m\n\u001b[0;32m    251\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    252\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 253\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\resnet.py:97\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[0;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[1;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    100\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1776\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1776\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1787\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1782\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1786\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1787\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1789\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1790\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:194\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    187\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:2846\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eps \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m   2844\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_norm eps must be positive, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00meps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 2846\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2849\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2854\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2855\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2856\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ---------------------------\n",
    "# Train / Eval utilities + Ablation study\n",
    "# ---------------------------\n",
    "def run_epoch(model, loader, criterion, optimizer=None):\n",
    "    train_mode = optimizer is not None\n",
    "    model.train() if train_mode else model.eval()\n",
    "\n",
    "    all_preds, all_targets = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(loader, leave=False):\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train_mode):\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            if train_mode:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        all_preds.append(preds.detach().cpu().numpy())\n",
    "        all_targets.append(labels.detach().cpu().numpy())\n",
    "\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    acc = accuracy_score(all_targets, all_preds)\n",
    "    avg_loss = running_loss / max(len(loader), 1)\n",
    "    return avg_loss, acc\n",
    "\n",
    "\n",
    "def train_single_model(model_name, model_factory):\n",
    "    model = model_factory().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=3)\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    epochs_no_improve = 0\n",
    "    save_file = f\"best_{model_name.lower().replace(' ', '_').replace('+', 'plus')}.pth\"\n",
    "    save_path = os.path.join(CHECKPOINT_DIR, save_file)\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        train_loss, train_acc = run_epoch(model, train_loader, criterion, optimizer=optimizer)\n",
    "        val_loss, val_acc = run_epoch(model, val_loader, criterion, optimizer=None)\n",
    "\n",
    "        scheduler.step(val_acc)\n",
    "\n",
    "        print(\n",
    "            f\"[{model_name}] Epoch {epoch:02d}/{EPOCHS} | \"\n",
    "            f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc * 100:.2f}% | \"\n",
    "            f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc * 100:.2f}%\"\n",
    "        )\n",
    "\n",
    "        if val_acc > best_val_acc + MIN_DELTA:\n",
    "            best_val_acc = val_acc\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"[{model_name}] Best model saved -> {save_path}\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "\n",
    "        if epochs_no_improve >= EARLY_STOPPING_PATIENCE:\n",
    "            print(f\"[{model_name}] Early stopping at epoch {epoch}\")\n",
    "            break\n",
    "\n",
    "    return {\n",
    "        'model_name': model_name,\n",
    "        'save_path': save_path,\n",
    "        'best_val_acc': best_val_acc,\n",
    "    }\n",
    "\n",
    "\n",
    "ablation_results = []\n",
    "for name, factory in model_factories.items():\n",
    "    print(f\"\\n{'='*25} Training: {name} {'='*25}\")\n",
    "    result = train_single_model(name, factory)\n",
    "    ablation_results.append(result)\n",
    "\n",
    "print('\\nAblation Summary (Validation):')\n",
    "for res in ablation_results:\n",
    "    print(f\"{res['model_name']:<18} | Best Val Acc: {res['best_val_acc'] * 100:.2f}%\")\n",
    "\n",
    "best_run = max(ablation_results, key=lambda x: x['best_val_acc'])\n",
    "print(f\"\\nSelected best model for test/evaluation: {best_run['model_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Test evaluation + confusion matrix + Grad-CAM\n",
    "# ---------------------------\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, loader, criterion):\n",
    "    model.eval()\n",
    "    preds_all, targets_all = [], []\n",
    "    running_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, leave=False):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            logits = model(images)\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            preds_all.append(logits.argmax(dim=1).cpu().numpy())\n",
    "            targets_all.append(labels.cpu().numpy())\n",
    "\n",
    "    preds_all = np.concatenate(preds_all)\n",
    "    targets_all = np.concatenate(targets_all)\n",
    "    avg_loss = running_loss / max(len(loader), 1)\n",
    "    acc = accuracy_score(targets_all, preds_all)\n",
    "    return avg_loss, acc, targets_all, preds_all\n",
    "\n",
    "\n",
    "def expected_ckpt_name(model_name):\n",
    "    return f\"best_{model_name.lower().replace(' ', '_').replace('+', 'plus')}.pth\"\n",
    "\n",
    "\n",
    "def find_checkpoint(filename):\n",
    "    primary_dir = CHECKPOINT_DIR if 'CHECKPOINT_DIR' in globals() else os.path.join(os.getcwd(), 'checkpoints')\n",
    "    search_dirs = [primary_dir, os.getcwd(), '/kaggle/working', '/content', '/root', '/tmp']\n",
    "    checked = []\n",
    "\n",
    "    for base in search_dirs:\n",
    "        if not os.path.isdir(base):\n",
    "            continue\n",
    "        checked.append(base)\n",
    "\n",
    "        direct = os.path.join(base, filename)\n",
    "        if os.path.exists(direct):\n",
    "            return direct, checked\n",
    "\n",
    "        matches = glob.glob(os.path.join(base, '**', filename), recursive=True)\n",
    "        if matches:\n",
    "            matches.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n",
    "            return matches[0], checked\n",
    "\n",
    "    return None, checked\n",
    "\n",
    "\n",
    "if 'model_factories' not in globals():\n",
    "    raise RuntimeError('model_factories is not defined. Run Cell 5 (model definitions) first.')\n",
    "\n",
    "if 'test_loader' not in globals() or 'class_names' not in globals() or 'test_dataset' not in globals():\n",
    "    raise RuntimeError('Data loaders/classes are not defined. Run Cell 4 (dataset + dataloaders) first.')\n",
    "\n",
    "if 'ablation_results' not in globals() or len(ablation_results) == 0:\n",
    "    reconstructed = []\n",
    "    all_checked = set()\n",
    "\n",
    "    for model_name in model_factories.keys():\n",
    "        expected_name = expected_ckpt_name(model_name)\n",
    "        ckpt_path, checked = find_checkpoint(expected_name)\n",
    "        all_checked.update(checked)\n",
    "\n",
    "        if ckpt_path is not None:\n",
    "            reconstructed.append({\n",
    "                'model_name': model_name,\n",
    "                'save_path': ckpt_path,\n",
    "                'best_val_acc': float('nan')\n",
    "            })\n",
    "            print(f\"Found checkpoint for {model_name}: {ckpt_path}\")\n",
    "\n",
    "    if len(reconstructed) == 0:\n",
    "        checked_list = ', '.join(sorted(all_checked)) if len(all_checked) else '(no valid directories found)'\n",
    "        raise RuntimeError(\n",
    "            'ablation_results is missing and no checkpoints were found. '\n",
    "            f'Searched under: {checked_list}. '\n",
    "            'Run Cell 6 now to generate checkpoints in CHECKPOINT_DIR.'\n",
    "        )\n",
    "\n",
    "    ablation_results = reconstructed\n",
    "    print(f\"Recovered ablation_results from {len(ablation_results)} saved checkpoint(s).\")\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "test_results = []\n",
    "for res in ablation_results:\n",
    "    if not os.path.exists(res['save_path']):\n",
    "        print(f\"Skipping missing checkpoint: {res['save_path']}\")\n",
    "        continue\n",
    "\n",
    "    name = res['model_name']\n",
    "    model = model_factories[name]().to(device)\n",
    "    model.load_state_dict(torch.load(res['save_path'], map_location=device))\n",
    "\n",
    "    test_loss, test_acc, y_true, y_pred = evaluate_model(model, test_loader, criterion)\n",
    "    test_results.append({\n",
    "        'model_name': name,\n",
    "        'test_loss': test_loss,\n",
    "        'test_acc': test_acc,\n",
    "        'y_true': y_true,\n",
    "        'y_pred': y_pred,\n",
    "    })\n",
    "\n",
    "if len(test_results) == 0:\n",
    "    raise RuntimeError('No evaluable checkpoints found. Run Cell 6 to produce best_*.pth files.')\n",
    "\n",
    "print('\\nAblation Summary (Test):')\n",
    "for tr in test_results:\n",
    "    print(f\"{tr['model_name']:<18} | Test Loss: {tr['test_loss']:.4f} | Test Acc: {tr['test_acc'] * 100:.2f}%\")\n",
    "\n",
    "best_test = max(test_results, key=lambda x: x['test_acc'])\n",
    "print(f\"\\nBest test model: {best_test['model_name']} ({best_test['test_acc'] * 100:.2f}%)\")\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(best_test['y_true'], best_test['y_pred'], target_names=class_names))\n",
    "\n",
    "cm = confusion_matrix(best_test['y_true'], best_test['y_pred'])\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "im = ax.imshow(cm, cmap='Blues')\n",
    "ax.set_title(f\"Confusion Matrix - {best_test['model_name']}\")\n",
    "ax.set_xlabel('Predicted')\n",
    "ax.set_ylabel('True')\n",
    "ax.set_xticks(np.arange(len(class_names)))\n",
    "ax.set_yticks(np.arange(len(class_names)))\n",
    "ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "ax.set_yticklabels(class_names)\n",
    "\n",
    "for i in range(cm.shape[0]):\n",
    "    for j in range(cm.shape[1]):\n",
    "        ax.text(j, i, cm[i, j], ha='center', va='center', color='black', fontsize=8)\n",
    "\n",
    "fig.colorbar(im, ax=ax)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "\n",
    "        self.fwd_handle = target_layer.register_forward_hook(self._forward_hook)\n",
    "        self.bwd_handle = target_layer.register_full_backward_hook(self._backward_hook)\n",
    "\n",
    "    def _forward_hook(self, module, inputs, output):\n",
    "        self.activations = output\n",
    "\n",
    "    def _backward_hook(self, module, grad_input, grad_output):\n",
    "        self.gradients = grad_output[0]\n",
    "\n",
    "    def generate(self, x, class_idx=None):\n",
    "        self.model.eval()\n",
    "        logits = self.model(x)\n",
    "\n",
    "        if class_idx is None:\n",
    "            class_idx = logits.argmax(dim=1).item()\n",
    "\n",
    "        score = logits[:, class_idx]\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        score.backward(retain_graph=True)\n",
    "\n",
    "        grads = self.gradients\n",
    "        acts = self.activations\n",
    "\n",
    "        weights = grads.mean(dim=(2, 3), keepdim=True)\n",
    "        cam = (weights * acts).sum(dim=1, keepdim=True)\n",
    "        cam = F.relu(cam)\n",
    "        cam = F.interpolate(cam, size=(IMG_SIZE, IMG_SIZE), mode='bilinear', align_corners=False)\n",
    "\n",
    "        cam = cam.squeeze().detach().cpu().numpy()\n",
    "        cam = (cam - cam.min()) / (cam.max() - cam.min() + 1e-8)\n",
    "        return cam, class_idx\n",
    "\n",
    "    def close(self):\n",
    "        self.fwd_handle.remove()\n",
    "        self.bwd_handle.remove()\n",
    "\n",
    "\n",
    "def denormalize(img_tensor):\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406], device=img_tensor.device).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225], device=img_tensor.device).view(3, 1, 1)\n",
    "    img = img_tensor * std + mean\n",
    "    return img.clamp(0, 1)\n",
    "\n",
    "\n",
    "best_model_name = best_test['model_name']\n",
    "best_model = model_factories[best_model_name]().to(device)\n",
    "best_model.load_state_dict(torch.load(next(r['save_path'] for r in ablation_results if r['model_name'] == best_model_name), map_location=device))\n",
    "\n",
    "sample_img, sample_label = test_dataset[0]\n",
    "input_tensor = sample_img.unsqueeze(0).to(device)\n",
    "\n",
    "target_layer = best_model.backbone.features[-1]\n",
    "grad_cam = GradCAM(best_model, target_layer)\n",
    "cam, pred_idx = grad_cam.generate(input_tensor)\n",
    "grad_cam.close()\n",
    "\n",
    "img_np = denormalize(sample_img.to(device)).permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(img_np)\n",
    "plt.title(f\"Input\\nTrue: {class_names[sample_label]}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(cam, cmap='jet')\n",
    "plt.title('Grad-CAM Heatmap')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(img_np)\n",
    "plt.imshow(cam, cmap='jet', alpha=0.45)\n",
    "plt.title(f\"Overlay\\nPred: {class_names[pred_idx]}\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab8921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Multiple-sample test + Grad-CAM visualization\n",
    "# ---------------------------\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if 'best_model' not in globals():\n",
    "    raise RuntimeError(\"Run Cell 7 first so best_model is loaded.\")\n",
    "if 'test_dataset' not in globals() or 'class_names' not in globals():\n",
    "    raise RuntimeError(\"Run Cell 4 first so test_dataset/class_names are available.\")\n",
    "\n",
    "NUM_SAMPLES = 8          # change this value as needed\n",
    "RANDOM_SAMPLES = True    # True = random samples, False = first N samples\n",
    "\n",
    "def predict_one(model, img_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(img_tensor.unsqueeze(0).to(device))\n",
    "        probs = torch.softmax(logits, dim=1).squeeze(0)\n",
    "        pred_idx = int(torch.argmax(probs).item())\n",
    "        conf = float(probs[pred_idx].item())\n",
    "    return pred_idx, conf\n",
    "\n",
    "num_available = len(test_dataset)\n",
    "if NUM_SAMPLES < 1:\n",
    "    raise ValueError(\"NUM_SAMPLES must be >= 1\")\n",
    "num_to_show = min(NUM_SAMPLES, num_available)\n",
    "\n",
    "if RANDOM_SAMPLES:\n",
    "    rng = random.Random(SEED)\n",
    "    sample_indices = rng.sample(range(num_available), k=num_to_show)\n",
    "else:\n",
    "    sample_indices = list(range(num_to_show))\n",
    "\n",
    "cols = 4\n",
    "rows = math.ceil(num_to_show / cols)\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 3.6 * rows))\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for plot_idx, ds_idx in enumerate(sample_indices):\n",
    "    img, label = test_dataset[ds_idx]\n",
    "    pred_idx, conf = predict_one(best_model, img)\n",
    "\n",
    "    target_layer = best_model.backbone.features[-1]\n",
    "    grad_cam = GradCAM(best_model, target_layer)\n",
    "    cam, _ = grad_cam.generate(img.unsqueeze(0).to(device), class_idx=pred_idx)\n",
    "    grad_cam.close()\n",
    "\n",
    "    img_np = denormalize(img.to(device)).permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "    ax = axes[plot_idx]\n",
    "    ax.imshow(img_np)\n",
    "    ax.imshow(cam, cmap='jet', alpha=0.40)\n",
    "    color = 'green' if pred_idx == label else 'red'\n",
    "    ax.set_title(\n",
    "        f\"Idx {ds_idx} | True: {class_names[label]}\\nPred: {class_names[pred_idx]} ({conf*100:.1f}%)\",\n",
    "        fontsize=9,\n",
    "        color=color\n",
    "    )\n",
    "    ax.axis('off')\n",
    "\n",
    "for j in range(num_to_show, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.suptitle(f\"Grad-CAM on {num_to_show} Test Samples\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
